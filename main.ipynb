{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from utils import generate_random_id\n",
    "\n",
    "from apikey import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "model = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Alice! Choosing the right colors for a data visualization can be quite challenging. Even though we both come from different professional backgrounds, we can agree that effective color selection is crucial for clear and accurate data communication. What specific difficulties have you encountered in selecting colors for your visualizations? Maybe we can come up with solutions together.\n",
      "\n",
      "Alice: Thanks, Bob! One major challenge I've faced is ensuring that the colors I choose are accessible to people with color vision deficiencies. Since around 8% of men and 0.5% of women of Northern European descent have some form of color blindness, it's crucial to design with them in mind. Have you encountered similar issues in your work?\n",
      "\n",
      "Bob: Absolutely, Alice. In the medical field, clear data representation is essential, especially when visualizing patient data or research findings. Color blindness is definitely a concern. One approach I use is employing color blind-friendly palettes, which can be found through various resources and tools online. \n",
      "\n",
      "Alice: That's a good tip, Bob. Another issue I've dealt with is balancing aesthetic appeal with functionality. Sometimes, colors that look visually appealing aren't necessarily the best for distinguishing different data points. \n",
      "\n",
      "Bob: Right, aesthetics can be tricky. In my experience, neutral backgrounds with more distinct, contrasting colors for data points often work well. Additionally, using texture or pattern alongside color for differentiation can also aid in clarity.\n",
      "\n",
      "Alice: Good idea. I've also noticed that cultural differences can impact color perception—certain colors carry different meanings in various cultures, which can affect the interpretation of data. For international audiences, that's another layer of complexity. Do you think about cultural implications in your medical visualizations?\n",
      "\n",
      "Bob: Definitely, cultural considerations are important, especially when presenting research at international conferences or working with diverse patient populations. For instance, while red might signify urgency in Western cultures, it might have positive connotations in others. Using color conventions that are universally understood, like traffic light colors for risk assessment, can mitigate misunderstandings.\n",
      "\n",
      "Alice: Excellent point. Something else I've struggled with is maintaining consistency across different visualizations, especially in larger projects with multiple charts or graphs. It's easy for a color scheme to become disorganized.\n",
      "\n",
      "Bob: Consistency is key. I find that creating a style guide for color usage can help maintain uniformity. It’s useful not just for individual projects but also for establishing a recognizable visual identity across different works.\n",
      "\n",
      "Alice: That's smart. Do you have any favorite software or tools that help you with color selection and ensuring consistency?\n",
      "\n",
      "Bob: Yes, I often use tools like ColorBrewer, which offers color schemes specifically designed for data visualization. Also, Adobe Color can be handy for creating and saving custom palettes. What about you, Alice?\n",
      "\n",
      "Alice: I use similar tools. ColorBrewer is fantastic for ensuring both color blindness accessibility and print visibility. I also like using Datawrapper, which provides some good default palettes and allows for custom color schemes.\n",
      "\n",
      "Bob: Sounds like we have some good strategies in place. Despite our different fields, it's clear that thoughtful color selection is universally important in data visualization.\n",
      "\n",
      "Alice: Absolutely, Bob. It's always great to share insights. Maybe we should collaborate on a project sometime and merge our expertise!\n",
      "\n",
      "Bob: That would be fantastic, Alice. Looking forward to it!\n",
      "\n",
      "Alice: It’s really encouraging to hear that even across different domains, the challenges and solutions can be quite similar. It shows how universally applicable good design principles are.\n",
      "\n",
      "Bob: Completely agree, Alice. Sometimes sharing perspectives from different fields can lead to innovative solutions we might not have thought of otherwise. For example, do you find that interactivity in visualizations changes how you think about color?\n",
      "\n",
      "Alice: Absolutely. When visualizations are interactive, the requirements for color can shift. You need to think about how colors will hold up when layers are added or removed, and how they interact when users hover or click on data points.\n",
      "\n",
      "Bob: That’s an interesting point. In my work, interactivity often comes into play with tools that allow users to explore individual patient data or dig deeper into specific aspects of research findings. Ensuring that the color signals remain clear throughout the interaction is vital.\n",
      "\n",
      "Alice: Have you found any effective strategies for testing your color choices before finalizing a visualization?\n",
      "\n",
      "Bob: One method I’ve found useful is getting feedback from colleagues or a test audience. They can offer fresh perspectives and might spot issues I’ve overlooked. Additionally, I use software that simulates color blindness to see how my visualizations will appear to those with color vision deficiencies.\n",
      "\n",
      "Alice: Testing is definitely important. I also like to use grayscale to check if the visualization still makes sense without color. This helps ensure that the information is accessible to people who can’t distinguish certain colors. \n",
      "\n",
      "Bob: That’s a great technique, Alice. Sometimes it’s easy to overlook how much we rely on color until we strip it away. \n",
      "\n",
      "Alice: Yes, and it helps reinforce that, while color is a powerful tool, it shouldn’t be the sole method of conveying information. Labels, annotations, and design elements like shapes play an important role too.\n",
      "\n",
      "Bob: Absolutely, redundancy in design helps ensure that the message gets across clearly regardless of any single factor’s limitations. \n",
      "\n",
      "Alice: Do you ever find the need to adjust colors for different mediums, like print versus digital displays?\n",
      "\n",
      "Bob: Oh, definitely. Colors can render very differently on a screen compared to print. Ensuring that the colors stay true across mediums often involves adjusting brightness and contrast settings and sometimes even choosing different palettes altogether. \n",
      "\n",
      "Alice: It’s quite a bit of work to manually adjust for those differences. Have you found any automated solutions that help with this?\n",
      "\n",
      "Bob: Some software options have settings for both print and digital outputs, which can help streamline adjustments. But manual tweaks are often necessary to ensure everything looks as intended.\n",
      "\n",
      "Alice: I’ve used some tools with print preview features, which has helped. But as you said, manual checks are usually essential to catch anything the software might miss. \n",
      "\n",
      "Bob: It’s a multifaceted challenge, but having a solid understanding of your tools and being open to feedback can make a significant difference.\n",
      "\n",
      "Alice: Absolutely. It’s reassuring to know that careful consideration and cross-field collaboration can help tackle these challenges effectively. \n",
      "\n",
      "Bob: Indeed, it’s been great exchanging ideas with you, Alice. \n",
      "\n",
      "Alice: Likewise, Bob. Let’s stay in touch and perhaps we can collaborate on a data visualization project someday.\n",
      "\n",
      "Bob: I’d love that. Take care, Alice!\n",
      "\n",
      "Alice: You too, Bob!\n",
      "\n",
      "Alice: It’s really encouraging to hear that even across different domains, the challenges and solutions can be quite similar. It shows how universally applicable good design principles are.\n",
      "\n",
      "Bob: Completely agree, Alice. Sometimes sharing perspectives from different fields can lead to innovative solutions we might not have thought of otherwise. For example, do you find that interactivity in visualizations changes how you think about color?\n",
      "\n",
      "Alice: Absolutely. When visualizations are interactive, the requirements for color can shift. You need to think about how colors will hold up when layers are added or removed, and how they interact when users hover or click on data points.\n",
      "\n",
      "Bob: That’s an interesting point. In my work, interactivity often comes into play with tools that allow users to explore individual patient data or dig deeper into specific aspects of research findings. Ensuring that the color signals remain clear throughout the interaction is vital.\n",
      "\n",
      "Alice: Have you found any effective strategies for testing your color choices before finalizing a visualization?\n",
      "\n",
      "Bob: One method I’ve found useful is getting feedback from colleagues or a test audience. They can offer fresh perspectives and might spot issues I’ve overlooked. Additionally, I use software that simulates color blindness to see how my visualizations will appear to those with color vision deficiencies.\n",
      "\n",
      "Alice: Testing is definitely important. I also like to use grayscale to check if the visualization still makes sense without color. This helps ensure that the information is accessible to people who can’t distinguish certain colors. \n",
      "\n",
      "Bob: That’s a great technique, Alice. Sometimes it’s easy to overlook how much we rely on color until we strip it away. \n",
      "\n",
      "Alice: Yes, and it helps reinforce that, while color is a powerful tool, it shouldn’t be the sole method of conveying information. Labels, annotations, and design elements like shapes play an important role too.\n",
      "\n",
      "Bob: Absolutely, redundancy in design helps ensure that the message gets across clearly regardless of any single factor’s limitations. \n",
      "\n",
      "Alice: Do you ever find the need to adjust colors for different mediums, like print versus digital displays?\n",
      "\n",
      "Bob: Oh, definitely. Colors can render very differently on a screen compared to print. Ensuring that the colors stay true across mediums often involves adjusting brightness and contrast settings and sometimes even choosing different palettes altogether. \n",
      "\n",
      "Alice: It’s quite a bit of work to manually adjust for those differences. Have you found any automated solutions that help with this?\n",
      "\n",
      "Bob: Some software options have settings for both print and digital outputs, which can help streamline adjustments. But manual tweaks are often necessary to ensure everything looks as intended.\n",
      "\n",
      "Alice: I’ve used some tools with print preview features, which has helped. But as you said, manual checks are usually essential to catch anything the software might miss. \n",
      "\n",
      "Bob: It’s a multifaceted challenge, but having a solid understanding of your tools and being open to feedback can make a significant difference.\n",
      "\n",
      "Alice: Absolutely. It’s reassuring to know that careful consideration and cross-field collaboration can help tackle these challenges effectively. \n",
      "\n",
      "Bob: Indeed, it’s been great exchanging ideas with you, Alice. \n",
      "\n",
      "Alice: Likewise, Bob. Let’s stay in touch and perhaps we can collaborate on a data visualization project someday.\n",
      "\n",
      "Bob: I’d love that. Take care, Alice!\n",
      "\n",
      "Alice: You too, Bob!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m    simulate_conversation(persona1, persona2, topic)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m    main()\n",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m persona2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBob: A 35-year-old medical doctor who is interested in data visualization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m topic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLet\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms talk about the difficulties of selecting the right colors for a data visualization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m simulate_conversation(persona1, persona2, topic)\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36msimulate_conversation\u001b[0;34m(persona1, persona2, topic, iterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m last_speaker \u001b[39m=\u001b[39m persona1\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[0;32m---> 17\u001b[0m    response \u001b[39m=\u001b[39m get_response(prompt1)\n\u001b[1;32m     18\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m    \u001b[39mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_response\u001b[39m(prompt):\n\u001b[0;32m----> 2\u001b[0m    completion \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4o\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m       messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}],\n\u001b[1;32m      5\u001b[0m    )\n\u001b[1;32m      6\u001b[0m    output \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m      7\u001b[0m    \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    591\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    592\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    593\u001b[0m             {\n\u001b[1;32m    594\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    595\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    596\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    597\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    598\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    599\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    600\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    601\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    615\u001b[0m             },\n\u001b[1;32m    616\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    617\u001b[0m         ),\n\u001b[1;32m    618\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    619\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    620\u001b[0m         ),\n\u001b[1;32m    621\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    622\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    623\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    624\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    922\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    923\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    924\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    925\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    926\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    927\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    949\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mSending HTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    951\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    953\u001b[0m         request,\n\u001b[1;32m    954\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    955\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    958\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Desktop/auto-podcast/venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1166\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_response(prompt):\n",
    "   completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "   )\n",
    "   output = completion.choices[0].message.content\n",
    "   return output\n",
    "\n",
    "def simulate_conversation(persona1, persona2, topic, iterations=10):\n",
    "   \"\"\"Simulate a conversation between two personas on a given topic.\"\"\"\n",
    "   conversation = []\n",
    "   \n",
    "   prompt1 = f\"{persona1}\\n{topic}\\n{persona2}\\n{persona1.split(':')[0]}: \"\n",
    "   last_speaker = persona1.split(':')[0]\n",
    "\n",
    "   for i in range(iterations):\n",
    "      response = get_response(prompt1)\n",
    "      print(f\"{response}\")\n",
    "      print()\n",
    "      if last_speaker == persona1.split(':')[0]:\n",
    "         current_speaker = persona2.split(':')[0]\n",
    "      else:\n",
    "         current_speaker = persona1.split(':')[0]\n",
    "\n",
    "      conversation.append({\n",
    "         \"name\": current_speaker,\n",
    "         \"order\": i + 1,\n",
    "         \"text\": response,\n",
    "         \"id\": generate_random_id()\n",
    "      })\n",
    "\n",
    "      prompt1 += f\"{current_speaker}: {response}\\n\"\n",
    "\n",
    "      last_speaker = current_speaker\n",
    "\n",
    "      df = pd.DataFrame(conversation)\n",
    "      df.to_csv(\"conversation.csv\", index=False)\n",
    "\n",
    "   return conversation\n",
    "\n",
    "def main():\n",
    "   persona1 = \"Alice: A 30-year-old journalist who is interested in data visualization.\"\n",
    "   persona2 = \"Bob: A 35-year-old medical doctor who is interested in data visualization.\"\n",
    "   topic = \"Let's talk about the difficulties of selecting the right colors for a data visualization.\"\n",
    "   simulate_conversation(persona1, persona2, topic)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
